{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7bd8c4e-a55d-4f1c-85fa-0f3fed703cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b14983f-4d88-4fa3-8183-7407939240fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8c9f5b-4a64-468a-bb08-5b45dc1116aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt2\"   \n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1174a83-a3dd-4f03-94ff-aabf389588c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is the new wave of computing. The first major breakthrough was in 1996, when Google began using machine learning to build its own artificial neural network that could work with humans as well as computers and robots (see \"How AI Could Make It Easier To Work\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Artificial intelligence is\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99dd692a-8800-40b9-8fc4-b2beb6799698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_new_tokens=80):\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ca6f2c-1427-4f9f-b9f4-17be49cacf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"\"\"The following is a conversation with an AI assistant.\n",
    "The assistant gives clear, helpful, and short answers.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff89420-2370-4839-a9ac-dadbc13942b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input):\n",
    "    global conversation\n",
    "\n",
    "\n",
    "    conversation += f\"User: {user_input}\\nAssistant:\"\n",
    "\n",
    "    response = generate_response(conversation)\n",
    "\n",
    "    assistant_reply = response[len(conversation):]\n",
    "\n",
    "    assistant_reply = assistant_reply.split(\"User:\")[0]\n",
    "\n",
    "    conversation += assistant_reply.strip() + \"\\n\"\n",
    "    return assistant_reply.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6a365e-d5cc-4757-b835-fa656030f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is Artificial Intelligence ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2: I'm talking to you about the future of human knowledge in space... You're right! Humanity has been exploring Earth for many years now - they've come up through all kinds...\" (Pause) \"How would we know what's going on there?\" \"It looks like it could be one day.\"\n",
      "-AI Assistant : How do you think this will change things? Where does our relationship go from\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Artificial intelligence is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2: A lot more intelligent than humans are at present ! I can see that eventually humanity might need artificial intelligences but not as much so long ago . They have very little power over us or ourselves because some people don't understand them properly..but maybe once someone learns how smart their own mind works then perhaps those computers may just start working themselves out rather quickly !!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "\n",
    "    reply = chat(user_input)\n",
    "    print(\"GPT-2:\", reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc223ae-2461-4b96-9d07-278bd4ea857e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
