{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3890022a-549d-4af2-9176-c4a9438b3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e51ec1-8ac3-4842-9feb-b7fae661d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9abade4e-73ad-409c-9da6-e1cf6333381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4963, 0.7682, 0.0885])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "print(torch.rand(3))\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01af3a03-8f87-4253-9301-91c3825072ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2\"   \n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4fba03-aedf-41a8-b6d0-61871a24307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is a new field of research that has been in the works for a while now. It is a field\n"
     ]
    }
   ],
   "source": [
    "text = \"Artificial intelligence is\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=20,\n",
    "        do_sample=False,   #Model always picks the most probable next token\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b3a8e48-8273-46ce-830c-abf2edf9751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66ab7cf-9609-4125-9649-605daacbfc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = model.transformer.h[0]\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0cc841-1046-43e7-b6bc-83211e6a9ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_fc weight shape: torch.Size([768, 3072])\n",
      "c_proj weight shape: torch.Size([3072, 768])\n"
     ]
    }
   ],
   "source": [
    "fc_weight = block.mlp.c_fc.weight      \n",
    "proj_weight = block.mlp.c_proj.weight  \n",
    "\n",
    "print(\"c_fc weight shape:\", fc_weight.shape)\n",
    "print(\"c_proj weight shape:\", proj_weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8597fed5-4a72-4739-8acb-fafdfeb29cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of c_fc: 216.8270721435547\n",
      "Frobenius norm of c_proj: 135.10826110839844\n"
     ]
    }
   ],
   "source": [
    "fc_fro_norm = torch.norm(fc_weight, p=\"fro\")\n",
    "proj_fro_norm = torch.norm(proj_weight, p=\"fro\")\n",
    "\n",
    "print(\"Frobenius norm of c_fc:\", fc_fro_norm.item())\n",
    "print(\"Frobenius norm of c_proj:\", proj_fro_norm.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4b60e11-eeda-48e4-95da-e8c8f9eff692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in c:\\users\\mahakisore\\miniconda3\\lib\\site-packages (0.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db350b56-af09-4200-9135-f9063ceac1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "def kronecker_decompose(W, m, n, k=1, niter=10):\n",
    "    \"\"\"\n",
    "    Van Loan Kronecker decomposition.\n",
    "    \n",
    "    W: weight matrix (torch.Tensor)\n",
    "    m, n: dimensions of first Kronecker factor\n",
    "    k: number of Kronecker factors (start with 1)\n",
    "    \"\"\"\n",
    "\n",
    "    out_dim, in_dim = W.shape\n",
    "    print(out_dim)\n",
    "    print(in_dim)\n",
    "\n",
    "    m2 = out_dim // m\n",
    "    n2 = in_dim // n\n",
    "\n",
    "    assert m * m2 == out_dim\n",
    "    assert n * n2 == in_dim\n",
    "\n",
    "\n",
    "    W_re = rearrange(\n",
    "        W,\n",
    "        '(m m2) (n n2) -> (m n) (m2 n2)',\n",
    "        m=m, m2=m2, n=n, n2=n2\n",
    "    )\n",
    "\n",
    "\n",
    "    U, S, V = torch.svd_lowrank(W_re, q=k, niter=niter)\n",
    "\n",
    "\n",
    "    A = rearrange(U, '(m n) k -> k m n', m=m, n=n)\n",
    "    B = rearrange(V, '(m2 n2) k -> k m2 n2', m2=m2, n2=n2)\n",
    "\n",
    "    scale = S.sqrt().view(-1, 1, 1)\n",
    "\n",
    "    return A * scale, B * scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac52c231-3751-428d-ba63-43a055bc2f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "3072\n",
      "A shape: torch.Size([1, 768, 1536])\n",
      "B shape: torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "A, B = kronecker_decompose(\n",
    "    fc_weight,\n",
    "    m=768,\n",
    "    n=1536,\n",
    "    k=1\n",
    ")\n",
    "\n",
    "print(\"A shape:\", A.shape)\n",
    "print(\"B shape:\", B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d158f644-00a1-49da-8ea1-838b25bfc154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([768, 3072])\n",
      "Reconstructed shape: torch.Size([768, 3072])\n"
     ]
    }
   ],
   "source": [
    "W_hat = torch.kron(A[0], B[0])\n",
    "\n",
    "print(\"Original shape:\", fc_weight.shape)\n",
    "print(\"Reconstructed shape:\", W_hat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9304f68-0d4f-4777-a562-8b05d38bde43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Frobenius norm: 216.8270721435547\n",
      "Reconstruction error: 151.0072479248047\n",
      "Relative error: 0.6964409351348877\n"
     ]
    }
   ],
   "source": [
    "recon_error = torch.norm(fc_weight - W_hat, p=\"fro\")\n",
    "orig_norm = torch.norm(fc_weight, p=\"fro\")\n",
    "\n",
    "print(\"Original Frobenius norm:\", orig_norm.item())\n",
    "print(\"Reconstruction error:\", recon_error.item())\n",
    "print(\"Relative error:\", (recon_error / orig_norm).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e450afdb-6cef-44f5-bc0b-4d40019d3f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original W Frobenius norm: 216.8270721435547\n",
      "Kronecker Ŵ Frobenius norm (before): 155.60047912597656\n",
      "Norm ratio (Ŵ / W): 0.7176247835159302\n"
     ]
    }
   ],
   "source": [
    "W_hat_norm_before = torch.norm(W_hat, p=\"fro\")\n",
    "W_orig_norm = torch.norm(fc_weight, p=\"fro\")\n",
    "\n",
    "print(\"Original W Frobenius norm:\", W_orig_norm.item())\n",
    "print(\"Kronecker Ŵ Frobenius norm (before):\", W_hat_norm_before.item())\n",
    "print(\"Norm ratio (Ŵ / W):\", (W_hat_norm_before / W_orig_norm).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e0c8fa-ea47-4afd-89e7-7bb2144a6525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive scaling factor α: 1.3934859037399292\n"
     ]
    }
   ],
   "source": [
    "alpha = W_orig_norm / W_hat_norm_before\n",
    "print(\"Adaptive scaling factor α:\", alpha.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e81a2c4b-fea5-4a89-8791-7247859182f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_alpha = torch.sqrt(alpha)\n",
    "\n",
    "A_norm = A * sqrt_alpha\n",
    "B_norm = B * sqrt_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e64e15a8-204a-4573-9d9b-e0621bb9616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed normalized shape: torch.Size([768, 3072])\n"
     ]
    }
   ],
   "source": [
    "W_hat_norm = torch.kron(A_norm[0], B_norm[0])\n",
    "\n",
    "print(\"Reconstructed normalized shape:\", W_hat_norm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d99b249-4e1f-4484-92b7-27267188277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Frobenius norm: 216.8270721435547\n",
      "Normalized Kronecker Frobenius norm: 216.82717895507812\n",
      "Absolute difference: 0.0001068115234375\n"
     ]
    }
   ],
   "source": [
    "new_norm = torch.norm(W_hat_norm, p=\"fro\")\n",
    "\n",
    "print(\"Original Frobenius norm:\", W_orig_norm.item())\n",
    "print(\"Normalized Kronecker Frobenius norm:\", new_norm.item())\n",
    "print(\"Absolute difference:\", abs(W_orig_norm - new_norm).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ded8cc75-5ccf-435b-a9ba-bc9aff4b5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class KroneckerLinear(nn.Module):\n",
    "    def __init__(self, A, B):\n",
    "        \"\"\"\n",
    "        A: (in_features, out_factor1)  → (768, 1536)\n",
    "        B: (1, out_factor2)            → (1, 2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.A = nn.Parameter(A)   # (768, 1536)\n",
    "        self.B = nn.Parameter(B)   # (1, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, 768)\n",
    "        \"\"\"\n",
    "\n",
    "        y = torch.matmul(x, self.A)\n",
    "        y = y.unsqueeze(-1) * self.B\n",
    "        y = y.reshape(y.shape[0], y.shape[1], -1)\n",
    "\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ceacb71-fcea-4f6f-9c04-3758bc9ae224",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fc = A_norm[0]  # (768, 1536)\n",
    "B_fc = B_norm[0]  # (1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f14b8726-7298-4627-b746-b805c3a54866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2MLP(\n",
      "  (c_fc): KroneckerLinear()\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_fc = model.transformer.h[0].mlp.c_fc\n",
    "model.transformer.h[0].mlp.c_fc = KroneckerLinear(A_fc, B_fc)\n",
    "print(model.transformer.h[0].mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfa429d7-7da1-4dc6-8128-5f32b7cd9944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Artificial intelligence is\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0671f27e-87b6-4f4b-b781-91c83a5a47c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 768])\n"
     ]
    }
   ],
   "source": [
    "block = model.transformer.h[0]\n",
    "proj_weight = block.mlp.c_proj.weight  # shape: (768, 3072)\n",
    "\n",
    "print(proj_weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3fa451f-16a8-42c9-8aa9-6f55642e7064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "3072\n"
     ]
    }
   ],
   "source": [
    "A_p, B_p = kronecker_decompose(\n",
    "    proj_weight.T,   # transpose\n",
    "    m=768,\n",
    "    n=1536,\n",
    "    k=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b29c951-7c37-40ed-84b4-b3980fc029da",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat_p = torch.kron(A_p[0], B_p[0])\n",
    "\n",
    "orig_norm_p = torch.norm(proj_weight.T, p=\"fro\")\n",
    "hat_norm_p = torch.norm(W_hat_p, p=\"fro\")\n",
    "\n",
    "alpha_p = orig_norm_p / hat_norm_p\n",
    "sqrt_alpha_p = torch.sqrt(alpha_p)\n",
    "\n",
    "A_p_norm = A_p * sqrt_alpha_p\n",
    "B_p_norm = B_p * sqrt_alpha_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b76d8ada-f4d5-4bfb-a1ed-47fca49f5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_proj = A_p_norm[0]  # (768, 1536)\n",
    "B_proj = B_p_norm[0]  # (1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f6c185e-facd-4863-a11a-9cf44c815231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KroneckerLinearProj(nn.Module):\n",
    "    def __init__(self, A, B):\n",
    "        \"\"\"\n",
    "        A: (out_features, mid)  → (768, 1536)\n",
    "        B: (1, 2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.A = nn.Parameter(A)\n",
    "        self.B = nn.Parameter(B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, 3072)\n",
    "        \"\"\"\n",
    "        # reshape: 3072 → (1536, 2)\n",
    "        x = x.view(x.shape[0], x.shape[1], -1, 2)\n",
    "\n",
    "        # apply B\n",
    "        x = (x * self.B).sum(dim=-1)  # → (batch, seq, 1536)\n",
    "\n",
    "        # apply A\n",
    "        x = torch.matmul(x, self.A.t())  # → (batch, seq, 768)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29d831ae-8407-4773-8925-67c79c1684e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.h[0].mlp.c_proj = KroneckerLinearProj(A_proj, B_proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2842bad-8957-443d-8ca0-e90205fcea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Artificial intelligence is\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "print(\"Logits shape:\", outputs.logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f4b73b2-97d6-40f9-b43c-486c2db67251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer_idx in range(len(model.transformer.h)):\n",
    "#     block = model.transformer.h[layer_idx]\n",
    "\n",
    "#     # ---- c_fc ----\n",
    "#     W_fc = block.mlp.c_fc.weight\n",
    "\n",
    "#     A_fc, B_fc = kronecker_decompose(\n",
    "#         W_fc,\n",
    "#         m=768,\n",
    "#         n=1536,\n",
    "#         k=1\n",
    "#     )\n",
    "\n",
    "#     W_hat_fc = torch.kron(A_fc[0], B_fc[0])\n",
    "#     alpha_fc = torch.norm(W_fc, p=\"fro\") / torch.norm(W_hat_fc, p=\"fro\")\n",
    "\n",
    "#     A_fc = A_fc * torch.sqrt(alpha_fc)\n",
    "#     B_fc = B_fc * torch.sqrt(alpha_fc)\n",
    "\n",
    "#     block.mlp.c_fc = KroneckerLinear(A_fc[0], B_fc[0])\n",
    "\n",
    "#     # ---- c_proj ----\n",
    "#     W_proj = block.mlp.c_proj.weight\n",
    "\n",
    "#     A_p, B_p = kronecker_decompose(\n",
    "#         W_proj.T,\n",
    "#         m=768,\n",
    "#         n=1536,\n",
    "#         k=1\n",
    "#     )\n",
    "\n",
    "#     W_hat_p = torch.kron(A_p[0], B_p[0])\n",
    "#     alpha_p = torch.norm(W_proj.T, p=\"fro\") / torch.norm(W_hat_p, p=\"fro\")\n",
    "\n",
    "#     A_p = A_p * torch.sqrt(alpha_p)\n",
    "#     B_p = B_p * torch.sqrt(alpha_p)\n",
    "\n",
    "#     block.mlp.c_proj = KroneckerLinearProj(A_p[0], B_p[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11d68e46-8711-4e1b-b627-bc2953f04729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "baseline_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7f62904-6085-4adb-8a17-3f8cbf316002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): KroneckerLinear()\n",
       "          (c_proj): KroneckerLinearProj()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_model = model  \n",
    "compressed_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ac0af89-5f89-4563-b7a1-55cdb59980ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Artificial intelligence is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_base = baseline_model(**inputs).logits\n",
    "    logits_comp = compressed_model(**inputs).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1827c8b-8e9c-4f58-a505-6df2f3379377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative logit difference: 0.4264727234840393\n"
     ]
    }
   ],
   "source": [
    "rel_diff = torch.norm(logits_base - logits_comp) / torch.norm(logits_base)\n",
    "print(\"Relative logit difference:\", rel_diff.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f120476-10b8-4db9-ba72-788e2b2d788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline next token:  a\n",
      "Compressed next token: ,\n"
     ]
    }
   ],
   "source": [
    "last_base = logits_base[0, -1]\n",
    "last_comp = logits_comp[0, -1]\n",
    "\n",
    "token_base = torch.argmax(last_base).item()\n",
    "token_comp = torch.argmax(last_comp).item()\n",
    "\n",
    "print(\"Baseline next token:\", tokenizer.decode([token_base]))\n",
    "print(\"Compressed next token:\", tokenizer.decode([token_comp]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e63266e-1ca1-460a-82f6-1f84a150be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 overlap: 1 / 10\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "topk_base = set(torch.topk(last_base, k).indices.tolist())\n",
    "topk_comp = set(torch.topk(last_comp, k).indices.tolist())\n",
    "\n",
    "overlap = len(topk_base & topk_comp)\n",
    "\n",
    "print(f\"Top-{k} overlap:\", overlap, \"/\", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831684a8-89dc-4231-a028-43a9bef3f939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
